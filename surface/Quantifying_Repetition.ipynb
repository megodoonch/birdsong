{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifying Repetition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**update 5 Oct** Following Stabler's suggestion, let's distinguish between repetition and copying. \n",
    "\n",
    "* **Repetition** is the occurrence of adjacent identical substrings, and hence is defined on the surface level (observed sentences) rather than on the level of the grammar.\n",
    "* **Copying** is when material is reproduced on the level of the grammar, in particular due to the application of a kind of copy rule. Hence \"copying\" is defined on the level of the grammar. Copying will certainly lead to repetition on the surface, but repetition is not necessarily due to copying; for example a pure bigram grammar that doesn't have a copy rule might yield repetition on the surface simply because a series of bigrams is repeated, by chance.\n",
    "\n",
    "Our main question here is: How can we quantify the amount of repetition that is going on in a particular sentence in a way that does not depend on the particular type of grammar under consideration? Simply given a sentence, is there a metric that quantifies the amount of repetition?\n",
    "\n",
    "The importance of having such a quantity that is independent of a particular type of grammar, is that we can ask whether the advantage of the Copy rule in a particular grammar can be explained by the observed repetition or not? Furthermore, we can establish baseline repetition quantities using permutation tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from misc import *\n",
    "import scipy.stats as st\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do an example. Suppose we are given the following sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence = \"aiw aix aiw aix aiw aix aiw aix\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One approach would be to list all possible substrings that could be the result of repeats because they are followed by an exact repetition. In the \"repetition list\" that is generated below, each tuple (i,n) means that there is a repetition starting at index i, of length n, i.e. that the substring (i,i+n) is identical to (i+n,i+2n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_repetitions(sentence):\n",
    "    copies = []\n",
    "    for i in range(len(sentence)-1):                   # loop over position in sentence\n",
    "        for n in range(1,((len(sentence)-i)//2)+1):     # loop over substrings\n",
    "            if sentence[i:i+n]==sentence[i+n:i+(2*n)]: # if we detect a repetition...\n",
    "                copies.append( (i,n) )\n",
    "    return copies\n",
    "\n",
    "repetitions = find_repetitions(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "repetitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of these repetitions overlap. And there is some redundancy: if we know that (0,2) is a repeat and (0,4) is a repeat, then (4,2) is necessarily also a repeat. As an illustration, here below we present the repeats, where the left hand sides are marked in red and the repeated instances in gray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n,(i,j) in enumerate(repetitions):\n",
    "    plt.plot([i,i+j],[n,n],color=\"darkred\",lw=5)\n",
    "    plt.plot([i+j,i+(2*j)],[n,n],color=\"darkgray\",lw=5)\n",
    "plt.xticks(np.arange(len(sentence))+.5,sentence)\n",
    "plt.xlim(-1,len(sentence)+1)\n",
    "plt.ylim(-.5,len(repetitions))\n",
    "plt.yticks([],[])         \n",
    "plt.title(\"Illustration of copies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we are interested in quantifying the total amount of repetition. One way would be to compute, for each repetition, the number of words that are copied, and then sum those for every word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_repetitions = len(repetitions)\n",
    "repeated_total = sum([ n for (_,n) in repetitions ])\n",
    "\n",
    "print (\"Total repeated material %i\"%repeated_total)\n",
    "print (\"Number of repetitions %i\"%n_repetitions)\n",
    "print (\"Avg # of words per repeat %.2f\"%(repeated_total/float(n_repetitions)))\n",
    "print (\"Amount of repeating per word %.2f\"%(repeated_total/float(len(sentence))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Corpus (CATH8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how much repetition is going on in the CATH8 corpus? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The file that contains the base corpus\n",
    "INPUT_FILE = \"../corpus/cath8.txt\"\n",
    "\n",
    "# Read the input file and obtain a list of list of strings, i.e. the list of sentences\n",
    "f = open(INPUT_FILE,'r')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "cath8 = [ l.strip().split(\" \") for l in lines ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_repeats = []\n",
    "\n",
    "perword = pd.DataFrame([])\n",
    "for i,sentence in enumerate(cath8):\n",
    "    repetitions = find_repetitions(sentence)\n",
    "    all_repeats += repetitions # append the copies to the existing big list\n",
    "    \n",
    "    n_repetitions = len(repetitions)\n",
    "    repeated_total = sum([ n for (_,n) in repetitions ])\n",
    "    \n",
    "    perword = pd.concat([perword,\n",
    "                         pd.DataFrame({\"sentence\":[\".\".join(sentence)],\n",
    "                                       \"length\":[len(sentence)],\n",
    "                                       \"total.repeated.material\":[repeated_total],\n",
    "                                       \"number.of.repetitions\":[n_repetitions],\n",
    "                                       \"n.words.per.repeat\":[(repeated_total/float(n_repetitions))],\n",
    "                                       \"repetitions.per.word\":[repeated_total/float(len(sentence))]\n",
    "                                       })])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of what this looks like for a few example sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perword.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totrep= list(perword[\"total.repeated.material\"])\n",
    "res = plt.hist(totrep,bins=range(int(max(totrep))+1))\n",
    "plt.xlabel(\"Total repeated material in a word\")\n",
    "plt.title(\"Total repetitions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few outliers with huge amounts of repetition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perword[ perword[\"total.repeated.material\"]>19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Had to do this by hand due to something that looks like a bug in plt.hist\n",
    "repetitions_lengths = [ n for (_,n) in all_repeats ]\n",
    "repetition_ls = np.array(list(set(repetitions_lengths)))\n",
    "amounts = [ len([ n for n in repetitions_lengths if n==c]) for c in repetition_ls ]\n",
    "\n",
    "maxc = max(repetitions_lengths)\n",
    "#bs = np.arange(maxc+1)\n",
    "#res = plt.hist(list(copies_lengths),bins=bs)\n",
    "plt.bar(repetition_ls-.4,amounts,width=.8)\n",
    "plt.xticks(repetition_ls,repetition_ls)\n",
    "#res = plt.hist(copies_lengths)\n",
    "#plt.xticks(bs+.5,bs)\n",
    "plt.xlabel(\"Repetition length (# of words)\")\n",
    "plt.title(\"Amount of repetition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are no repetitions of length more than 6 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of copied words in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum([ n for (_,n) in all_repeats ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import quantify_copying\n",
    "cath8copy = quantify_copying.corpus(cath8)\n",
    "print (cath8copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repetition for various prefix lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, enter Meaghan, who wonders how repetition might depend on the prefix length. That is, if we have a prefix of length n, what are possible copies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rep_lengths = {}\n",
    "prefixes = range(1,max([len(s) for s in cath8]))\n",
    "repetition_prefix = np.array([ [ np.nan for _ in prefixes ] for _ in prefixes ])\n",
    "\n",
    "for prefix_length in prefixes:\n",
    "\n",
    "    # Go through all repetitions and find those where the prefix (the point 'between' the two repetitions) is 5. \n",
    "    # Note that I've encoded repetitions as (i,n) meaning that substring from i to i+n is the same as from i+n to i+2n.\n",
    "    selections = [ (i,n) for (i,n) in all_repeats if i+n==prefix_length ]\n",
    "    \n",
    "    # Now aggregate them by repetition length\n",
    "    repetition_lengths = np.arange(prefix_length)+1\n",
    "    n_repeats_per_length = [ len([ (i,n) for (i,n) in selections if n==rep_len ]) for rep_len in repetition_lengths ]\n",
    "    rep_lengths[prefix_length]=n_repeats_per_length    \n",
    "    \n",
    "    for rep_len in repetition_lengths:\n",
    "        repetition_prefix[prefix_length-1][rep_len-1]= len([ (i,n) for (i,n) in selections if n==rep_len ])\n",
    "    \n",
    "    #print (\"Prefix length: %i --\"%prefix_length)\n",
    "    #print (\"Repeats by repetition length:\",n_repeats_per_length)\n",
    "    \n",
    "    #rep_lengths[prefix_length]=n_repeats_per_length\n",
    "repetition_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is that same thing in graph form. As expected, the longest repeats happen in intermediate length sentences, because then you have enough material before to repeat and enough \"space\" after to insert the repeated stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(7,6))\n",
    "ax = plt.subplot(111,axisbg='darkgray')\n",
    "cax = ax.imshow(repetition_prefix,interpolation='None')\n",
    "ax.set_xlabel(\"Repetition length (# of words)\")\n",
    "ax.set_ylabel(\"Prefix length (# of words)\")\n",
    "plt.yticks(range(len(repetition_prefix)),   np.arange(len(repetition_prefix))+1)\n",
    "plt.xticks(range(len(repetition_prefix[0])),np.arange(len(repetition_prefix[0]))+1)\n",
    "#              [ i+1 for i in range(len(repetition_prefix))])\n",
    "f.colorbar(cax,label=\"# of repetitions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here below the same thing, but rescaling by the total number of copies for each prefix length. So we see a \"breakdown\" of repetition lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nona_sum(x): \n",
    "    v = [ i for i in x if not np.isnan(i) ]\n",
    "    if len(v)>0: \n",
    "        return sum(v)\n",
    "    else: \n",
    "        return 0.\n",
    "f = plt.figure(figsize=(7,6))\n",
    "ax = plt.subplot(111,axisbg='darkgray')\n",
    "rep_rescaled = [ repetition_prefix[i]/nona_sum(repetition_prefix[i]) for i in range(len(repetition_prefix)) ]\n",
    "cax = ax.imshow(rep_rescaled,interpolation='None')\n",
    "ax.set_xlabel(\"Repetition length (# of words)\")\n",
    "ax.set_ylabel(\"Prefix length (# of words)\")\n",
    "plt.yticks(range(len(repetition_prefix)),np.arange(len(repetition_prefix))+1)\n",
    "f.colorbar(cax,label=\"Proportion of repetitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from misc import *\n",
    "cols = get_colors(len(prefixes))\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for prefix_length in prefixes:\n",
    "    \n",
    "    sels = rep_lengths[prefix_length]\n",
    "        \n",
    "    plt.bar((float(prefix_length)/len(prefixes))+np.arange(len(sels))+1,\n",
    "            sels,\n",
    "            color=cols[prefix_length-1],edgecolor=cols[prefix_length-1],width=(1.0/len(prefixes)),\n",
    "            alpha=.6,label=prefix_length)\n",
    "    #.set_title(\"Prefix length %i\"%(prefix_length))\n",
    "\n",
    "plt.xlabel(\"Repetition length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Repetition length by prefix length\")\n",
    "plt.legend(title=\"Prefix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from misc import *\n",
    "fig, axs = plt.subplots(len(prefixes), 1, sharex=True, sharey=True,figsize=(8,9.5))\n",
    "cols = get_colors(len(prefixes))\n",
    "\n",
    "for prefix_length in prefixes:\n",
    "    \n",
    "    ax = axs[prefix_length-1]\n",
    "    sels = rep_lengths[prefix_length]\n",
    "        \n",
    "    ax.bar(range(1,len(sels)+1),\n",
    "           sels,\n",
    "           color=cols[prefix_length-1],edgecolor=cols[prefix_length-1],width=.8)\n",
    "    ax.set_title(\"Prefix length %i\"%(prefix_length))\n",
    "\n",
    "plt.xlabel(\"Repetition length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-syllable repeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "At SfN today (16.11.2014) I saw a poster by Wittenbach and Brainard and others and they noticed repetition on a single-syllable basis. What they noticed was that with Markov chains, you can get this kind of repetition, but only with decreasing probability for increasing repetition, i.e. A and AA and AAA and AAAA have monotonically decreasing probabilities. In reality, they found that at ~8 repetitions there was a maximum. This made me wonder how our single syllable repeats are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def single_syll_repeats(sentence):\n",
    "    copies = []\n",
    "    i = 0\n",
    "    while i<len(sentence):\n",
    "        n = i\n",
    "        while n<len(sentence) and sentence[n]==sentence[i]:\n",
    "            n+=1 # increase count\n",
    "        if n>i:\n",
    "            copies.append( (sentence[i],i,n-i) )\n",
    "        i=n\n",
    "    return copies\n",
    "\n",
    "single_syll_repeats(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allreps = []\n",
    "for sentence in cath8:\n",
    "    allreps+=single_syll_repeats(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we plot the number of repeats for various syllables (each line is a syllable). We restrict our attention to syllables that occur relatively often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, determine which syllables occur often enough to be of interest\n",
    "whole_corpus = []\n",
    "for s in cath8:\n",
    "    whole_corpus+=s\n",
    "\n",
    "unigram_freqs = get_freqs(whole_corpus)\n",
    "\n",
    "unigrams_selected = [ u for (u,cnt) in unigram_freqs if cnt>80 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we plot the repeat curves for the selected unigrams\n",
    "colors = get_colors(len(unigrams_selected))\n",
    "\n",
    "lengths = list(set([ l for (_,_,l) in allreps ]))\n",
    "for j,unigr in enumerate(unigrams_selected):\n",
    "    freqs = [ len([ i for (u,i,l) in allreps if l==length and u==unigr ]) for length in lengths ]\n",
    "    plt.plot( lengths, freqs, label=unigr, color=colors[j], lw=2 )\n",
    "\n",
    "plt.xticks( np.array(lengths)+.5, lengths )\n",
    "plt.xlabel(\"Number of unique syllable repeats\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the repeat lengths for all syllables taken together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lengths = list(set([ l for (_,_,l) in allreps ]))\n",
    "freqs = [ len([ i for (_,i,l) in allreps if l==length ]) for length in lengths ]\n",
    "plt.bar( lengths, freqs )\n",
    "plt.xticks( np.array(lengths)+.5, lengths )\n",
    "plt.xlabel(\"Number of unique syllable repeats\")\n",
    "plt.ylabel(\"Frequency\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, so I don't think there's evidence for single-syllable repeating being specially controlled (other than markov chains I guess). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copying in Randomly Generated Corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how much repetition is going on in the permuted corpora? And in the bigram-generated corpora? As a further check we also generate a corpus using bigrams, but this time we don't impose any length requirements on the individual words: we just randomly walk through our bigram transition matrix, generating words, and stopping when we have a corpus of approximately the same number of words as CATH8.\n",
    "\n",
    "As control analysis, we verify whether our length criteria might have led to this amount of repetition. To check this, we include a bigram grammar that has no length restrictions on words. As another control analysis, we generate a corpus from a \"flattened\" bigram grammar in which all bigrams are equiprobable. Finally, I also include our bootstrap coropra, which should have approximately the same amount of repetition as CATH8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generated by randomise.py\n",
    "perm_stats      = pd.DataFrame.from_csv('interim/permutations_stats.csv')\n",
    "\n",
    "# Generated by randomise_by_bigrams.py\n",
    "bigr_stats      = pd.DataFrame.from_csv('interim/bigramgen_corpus_stats.csv') \n",
    "# bigram-selected sentences selected such that they have the same distribution of sentence lengths\n",
    "\n",
    "# Generated by randomise_by_bigrams_free.py\n",
    "bigr_free_stats = pd.DataFrame.from_csv('interim/bigramgen_free_corpus_stats.csv') \n",
    "# bigram-generated sentences that have no restriction on distribution of sentence lengths\n",
    "\n",
    "# Generated by randomise_by_bigrams_free_flat.py\n",
    "bigr_free_flat_stats = pd.DataFrame.from_csv('interim/bigramgen_free_flat_corpus_stats.csv') \n",
    "# bigram-generated sentences with flat distribution: all bigrams are equally likely\n",
    "\n",
    "# Generated by randomise.py\n",
    "bootstr_stats      = pd.DataFrame.from_csv('interim/bootstrap_corpora_stats.csv')\n",
    "\n",
    "# Generated by randomise_within_sentences.py\n",
    "perm_within_stats  = pd.DataFrame.from_csv('interim/permutations_within_sentences_stats.csv')\n",
    "\n",
    "# The original corpus, generated by orig8_corpus_stats.py\n",
    "cath8_orig = pd.DataFrame.from_csv('interim/cath8_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perm_stats[\"corpus\"]          =\"Permutation corpora\"\n",
    "bigr_stats[\"corpus\"]          =\"Bigram-generated corpora (sentence length matched)\"\n",
    "bigr_free_stats[\"corpus\"]     =\"Bigram-generated corpora (approx.corpus size matched)\"\n",
    "bigr_free_flat_stats[\"corpus\"]=\"Bigram-generated corpora (flat: all bigrams equiprobable)\"\n",
    "bootstr_stats[\"corpus\"]       =\"Bootstrap corpora from CATH8\"\n",
    "perm_within_stats[\"corpus\"]   =\"Within-sentence permutations of CATH8\"\n",
    "\n",
    "fullstats = pd.concat([perm_stats,bigr_stats,bigr_free_stats,bigr_free_flat_stats,bootstr_stats,perm_within_stats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bycorpus = fullstats.groupby('corpus')\n",
    "#bycorpus[\"total.repeated.material\"].describe()\n",
    "summ = bycorpus[\"total.repeated.material\"].agg({\"N\":len,\"min\":min,\"mean\":np.mean,\"SD\":np.std,\"max\":max})\n",
    "summ[\"cath8.zscore\"]=(cath8copy[\"total.repeated.material\"]-summ[\"mean\"])/(summ[\"SD\"])\n",
    "summ[\"cath8.pvalue\"] = 1-st.norm.cdf(abs(summ[\"cath8.zscore\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a table with, for each corpus, the specification of the amount of repetition (minimum, maximum, mean, standard deviation of total repetition in the corpus). Also, the z-score of cath8 relative to these distributions is given, and the corresponding p-value (one-tailed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalcop   = list(perm_stats[\"total.repeated.material\"])\n",
    "bigrcop    = list(bigr_stats[\"total.repeated.material\"])\n",
    "bigrcopfr  = list(bigr_free_stats[\"total.repeated.material\"])\n",
    "bigrcopfrfl= list(bigr_free_flat_stats[\"total.repeated.material\"])\n",
    "bootstrcop = list(bootstr_stats[\"total.repeated.material\"])\n",
    "permwcop   = list(perm_within_stats[\"total.repeated.material\"])\n",
    "\n",
    "\n",
    "maxcop = max(bootstrcop+totalcop+bigrcop+[cath8copy[\"total.repeated.material\"]]#+bigrcopfr+bigrcopfrfl\n",
    "             )\n",
    "\n",
    "bins = np.linspace(0,maxcop,maxcop/25)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.hist(totalcop,bins=bins,color=\"darkblue\",edgecolor=\"darkblue\",\n",
    "         label=\"Permutation corpora\",alpha=.8)\n",
    "plt.hist(bigrcop,bins=bins,color=\"darkgreen\",edgecolor=\"darkgreen\",\n",
    "         label=\"Bigram-generated corpora (sentence length matched)\",alpha=.8)\n",
    "plt.hist(bigrcopfr,bins=bins,color=\"darkgray\",edgecolor=\"darkgray\",\n",
    "         label=\"Bigram-generated corpora (approx.corpus size matched)\",alpha=.8)\n",
    "plt.hist(bigrcopfrfl,bins=bins,color=\"purple\",edgecolor=\"purple\",\n",
    "         label=\"Bigram-generated corpora (flat: all bigrams equiprobable)\",alpha=.8)\n",
    "plt.hist(bootstrcop,bins=bins,color=\"darkred\",edgecolor=\"darkred\",\n",
    "         label=\"Bootstrap corpora from CATH8\",alpha=.3)\n",
    "plt.hist(permwcop,bins=bins,color=\"orange\",edgecolor=\"orange\",\n",
    "         label=\"Within-sentence permutations of CATH8\",alpha=.8)\n",
    "plt.axvline(x=cath8copy[\"total.repeated.material\"],color=\"darkred\",lw=2.5,label=\"CATH8\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Total repeated material in the corpus (# of words)\")\n",
    "plt.title(\"Quantifying repetition for various corpora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = \"Bootstrap corpora from CATH8\"\n",
    "sns.set_style(\"ticks\")\n",
    "sns.distplot(fullstats[ fullstats[\"corpus\"]==c ][\"total.repeated.material\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(12,5))\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_palette(sns.hls_palette(8, l=.3, s=.8))\n",
    "for c in list(set(fullstats[\"corpus\"])):\n",
    "    subs = fullstats[ fullstats[\"corpus\"]==c ][\"total.repeated.material\"]\n",
    "    sns.distplot(subs,label=c)\n",
    "ylim(0,.025)\n",
    "sns.despine()\n",
    "legend()\n",
    "axvline(x=cath8copy[\"total.repeated.material\"],color=\"darkred\",lw=2.5,label=\"CATH8\")\n",
    "xlabel(\"Total repeated material in the corpus (# of words)\")\n",
    "title(\"Quantifying repetition for various corpora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side-track** Does having more words in the corpus mean there will be more repetition? Recall that due to dropping the sentence-length restrictions, we now generate corpora of approximately the same size as CATH8, but not exactly. So is the final length of the corpus a predictor for the amount of repetition? (And is this a linear increase or something else?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(bigr_free_stats[\"n.corpus.words\"]+random.normal(0,.4,len(bigr_free_stats)),\n",
    "         bigr_free_stats[\"total.repeated.material\"],\n",
    "         'o',\n",
    "         alpha=.8,markersize=1.9,mec=\"darkgreen\",mfc=\"darkgreen\")\n",
    "plt.ylabel(\"Total repeated material\")\n",
    "plt.xlabel(\"Number of words in the corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems the relationship is not dramatic. This means we don't need to worry to much about the exact corpus size (plus or minus one word).\n",
    "\n",
    "As another check: did we get up with approximately the right number of sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(bigr_free_stats[\"n.sentences\"]+random.normal(0,.4,len(bigr_free_stats)),\n",
    "         bigr_free_stats[\"n.unique.sentences\"]+random.normal(0,.4,len(bigr_free_stats)),\n",
    "         'o',\n",
    "         alpha=.8,markersize=1.9,mec=\"darkgreen\",mfc=\"darkgreen\",label=\"bigram (free length) generated corpora\")\n",
    "plt.plot(cath8copy[\"n.sentences\"],\n",
    "         cath8copy[\"n.unique.sentences\"],'s',mec=\"darkred\",mfc=\"darkred\",markersize=8,label=\"CATH8\")\n",
    "plt.ylabel(\"Number of sentences in the corpus\")\n",
    "plt.xlabel(\"Number of unique sentences in the corpus\")\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side-track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A side-track: how many unique bigrams do we find in each of the randomisations mentioned above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randomisations = [(perm_stats,\"Permutation corpora\"),\n",
    "                  (bigr_stats,\"Bigram-generated corpora (sentence length matched)\"),\n",
    "                  (bigr_free_stats,\"Bigram-generated corpora (approx.corpus size matched)\"),\n",
    "                  (bigr_free_flat_stats,\"Bigram-generated corpora (flat: all bigrams equiprobable)\"),\n",
    "                  (bootstr_stats,\"Bootstrap corpora from CATH8\"),\n",
    "                  (perm_within_stats,\"Within-sentence permutations of CATH8\")]\n",
    "\n",
    "quantity = \"n.unique.bigrams\"\n",
    "\n",
    "report = []\n",
    "for (distr,lbl) in randomisations+[(cath8_orig,\"CATH8 original\")]:\n",
    "    vals = distr[quantity]\n",
    "    m,s = np.mean(vals),np.std(vals)\n",
    "    report.append( (lbl,m,s) )\n",
    "    \n",
    "report = pd.DataFrame(report)\n",
    "report.columns = [\"corpus\",\"M.%s\"%quantity,\"SD.%s\"%quantity]\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our conclusions so far\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We introduce a **repetition metric** that quantifies how much material is repeated in a sentence (with the restriction that repeated material must be adjacent in the string). This metric is shown to be robust as evident from bootstrap-generated corpora, which yield similar amounts of repetition centered around the observed value for CATH8.\n",
    "* Using our repetition metric, we are able to show that indeed permuted corpora have much less repetition. Still, they have a bit, but not as much as CATH8.\n",
    "* When we use the observed bigram frequencies to randomly generate new corpora (with the same sentence lengths as CATH8) we find that they have **more** repetition than CATH8. This is surprising! It seems to suggest that repetition, in some cases, might be an epiphenomenon of bigram frequency structure. Except that if CATH8 were really a bigram-bird (i.e. emitting randomly according to bigram frequencies), we would expect it to repeat more than it actually does!\n",
    "* This **bigram-induced repetition** appears to be encoded in the transitional probabilities rather than in the subset of legal bigrams (because if we \"flatten\" their distribution we don't observe as much repetition as CATH8 anymore)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantages of this metric are:\n",
    "(i) it's a-theoretic, making no assumptions about bigram structure or probabilistic structure,\n",
    "(ii) it's directly and straightforwardly calculated based on the observables; in particular it doesn't get stuck in potential local minima as the IO (EM) algorithm applied ot a grammar could.\n",
    "(iii) it allows \"fair\" comparison of amount of repetition on corpora that have very different structure (e.g. very different bigram distributions).\n",
    "(iv) it gives an \"absolute\" value of copying, instead of relative to something else, as is the case with the Bigram+Copy and Bigram grammars.\n",
    "The disadvantages:\n",
    "(i) it doesn't take into account that some of the repetitions mentioned above could overlap.\n",
    "(ii) it doesn't reflect whether some of these repetition-parses may be more or less likely (one might argue that very long repetitions are less likely).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
