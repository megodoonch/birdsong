{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Random is Random?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the question may arise how random the corpora are that we use to validate our results. \n",
    "We have several ways of generating random corpora, such as the permutation (which we previously used to validate fitting results). This permutation was set up in such a way to control for word length and unigram frequencies, but not bigram frequencies. \n",
    "\n",
    "Here we try to quantify unigram and bigram frequency distribution differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import compare_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing unordered categorical distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we quantify how close two unigram distributions are? Or how close to bigram distributions are?\n",
    "Really what we are comparing is how one group is distributed over a number of unordered categorical (discrete) variables, relative to a second group.\n",
    "\n",
    "So for example, here are the unigram distributions of the original corpus, together with those in a bootstrapped version of the corpus. In bootstrapping, we generate a new corpus by randomly choosing (with replacement) a sentence from the corpus, and add it to our bootstrap corpus. We keep going until our bootstrap corpus has the same number of sentences as the original corpus. Since we work with replacement, we will end up with a slightly different distribution of unigrams and bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the input file and obtain a list of list of strings, i.e. the list of sentences\n",
    "INPUT_FILE = \"../corpus/cath8.txt\"\n",
    "f = open(INPUT_FILE,'r')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "cath8 = [ l.strip().split(\" \") for l in lines ]\n",
    "\n",
    "original_unigrams = compare_bigrams.unigram_counts( cath8 )\n",
    "\n",
    "# Take a bootstrap sample\n",
    "bootstrap_corpus = []\n",
    "for j in range(len(cath8)):\n",
    "    bootstrap_corpus.append( random.choice(cath8) )\n",
    "    \n",
    "bootstrap_unigrams = compare_bigrams.unigram_counts( bootstrap_corpus )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All we have to do is generate a common set of bigrams\n",
    "all_ngrams = list({**original_unigrams,**bootstrap_unigrams}.keys())\n",
    "# ... and then evaluate each according to this common set,\n",
    "# substituting zero if the bigram in question does not occur\n",
    "orig_counts    = list(map(lambda x: original_unigrams.get(x,0),all_ngrams))\n",
    "bootstr_counts = list(map(lambda x: bootstrap_unigrams.get(x,0),all_ngrams))\n",
    "\n",
    "unigrams = pd.DataFrame({'ngram':all_ngrams,'orig.count':orig_counts,'bootstr.counts':bootstr_counts})\n",
    "unigrams[\"total.counts\"]=unigrams[\"orig.count\"]+unigrams[\"bootstr.counts\"]\n",
    "unigrams = unigrams.sort('total.counts',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "x = np.arange(len(all_ngrams))\n",
    "plt.bar(x+.3,unigrams[\"orig.count\"], width=.3,edgecolor=\"darkred\",color=\"darkred\")\n",
    "plt.bar(x,unigrams[\"bootstr.counts\"],width=.3,edgecolor=\"darkblue\",color=\"darkblue\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Unigram (ordered by # of occurrence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeballing it, the distributions seem fairly similar. There are some unigrams where differences are somewhat bigger, but that is to be expected by chance. Similarly, in some of the low-frequency unigrams, the bootstrap corpus simply didn't capture the one or two sentences that contained that unigram, and therefore would miss it altogether."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice metric to capture similarity of distributions is chi-squared. It looks at the two corpora as columns in a contingency table where the rows are the unigrams. Kind of like this, for illustration, for the highest-frequency unigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigrams.iloc[:10][[\"ngram\",\"orig.count\",\"bootstr.counts\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if the two corpora are identically distributed, the two columns should be independent. Note that the columns may sum to different numbers of items, but that will not affect whether they are independent and should not affect our metric of similarity of distribution. The chi-square metric has exactly that property. It computes the marginal sums (the sums of the rows and columns) and computes the expected number of items in each cell. Then, it computes how far the actual number in each cell deviates from the expected, and that results in the chi square measure.\n",
    "\n",
    "In our case we get the following chi-squared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comp = compare_bigrams.compare_Ngrams( original_unigrams, bootstrap_unigrams )\n",
    "print (comp[\"chisq\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the chi squared measure is unbounded, it takes arbitrary large values if the number of items in the table increases. It is therefore more elegant to use a \"normalised\" version, which is Cramer's V.\n",
    "For details: http://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V\n",
    "\n",
    "The neat property of this quantity is that it is in the range from 0 (meaning identical distributions, in our case) to 1.0 (meaning completely different distributions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (comp[\"cramer.V\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permuted Corpora Bigram Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we now have the tools to investigate similarity of distributions. In our previous analysis, we used a clever randomisation procedure in which we permuted the words in the corpus, keeping sentence boundaries intact. In this way, we have an identical distribution of unigrams and sentence lengths, but not bigrams. So how far off are the bigrams?\n",
    "\n",
    "Here are some 10k permutations and the corresponding Cramer V values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bootstraps = pd.DataFrame.from_csv('interim/bootstrap_corpora_stats.csv')\n",
    "permutations = pd.DataFrame.from_csv('interim/permutations_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0,.9,500)\n",
    "plt.figure(figsize=(13,5))\n",
    "plt.hist(list(permutations[\"bigrams.cramer.V\"]),bins,color=\"darkblue\",edgecolor=\"darkblue\",alpha=.9,label=\"permuted\")\n",
    "plt.hist(list(bootstraps[\"bigrams.cramer.V\"]),bins,color=\"darkred\",edgecolor=\"darkred\",alpha=.9,label=\"bootstraps\")\n",
    "plt.xlabel(\"Bigram distributions dissimilarity (Cramer V)\")\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the permuted corpora have very different bigram distributions, relative to bootstrap samples of similar size. I had this idea we could \"cherry-pick\" some permutations that have reasonably good bigram distributions, but as you can see there is really no hope we'll ever get even close to the bootstrap samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram-generated corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here is another try to get randomised corpora for our testing, trying to approach the bigram distributions more closely. The idea is as follows. We first generate a transition matrix from the bigrams observed in the corpus. We also count word boundaries in these bigrams, e.g. \"#.aiw\" is a bigram, indicating the aiw occurs initially with a particular probability.\n",
    "\n",
    "Then, we use this transition matrix to start generating a humongous set of sentences of all sorts of lengths. In this way, we hope to approximate the distribution of bigrams as observed in the real corpus.\n",
    "\n",
    "Then, we generate corpora from this set by choosing for each sentence in the real corpus a sentence from this randomised supercorpus with the same length. In this way, we make sure we have a randomised corpus with the same number of (1) words, (2) sentences, (3) and sentence lengths, but not necessarily the same unigram or bigram distributions.\n",
    "\n",
    "In order to check whether these come close to the real corpus (again, taking the bootstrap samples as our \"ground truth\"), here are the Cramer V's for the unigram and bigram frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bootstraps = pd.DataFrame.from_csv('interim/bootstrap_corpora_stats.csv')\n",
    "bigramgens = pd.DataFrame.from_csv('interim/bigramgen_corpus_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0,.3,100)\n",
    "plt.figure()\n",
    "plt.hist(list(bigramgens[\"bigrams.cramer.V\"]),bins,color=\"darkblue\",alpha=.7,label=\"bigram-generated\")\n",
    "plt.hist(list(bootstraps[\"bigrams.cramer.V\"]),bins,color=\"darkred\",alpha=.7,label=\"bootstraps\")\n",
    "plt.xlabel(\"Bigram distributions dissimilarity (Cramer V)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(list(bigramgens[\"unigrams.cramer.V\"]),bins,color=\"darkblue\",alpha=.7,label=\"bigram-generated\")\n",
    "plt.hist(list(bootstraps[\"unigrams.cramer.V\"]),bins,color=\"darkred\",alpha=.7,label=\"bootstraps\")\n",
    "plt.xlabel(\"Unigram distributions dissimilarity (Cramer V)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is encouraging. The two distributions still don't completely overlap, but that could be taken care of\n",
    "by setting appropriate cutoffs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of unique bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a difference in number of bigrams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_bigrams = compare_bigrams.bigram_counts( cath8 )\n",
    "n_cath8_bigrams = len(original_bigrams.keys())\n",
    "\n",
    "bins = np.linspace(0,1900,500)\n",
    "plt.figure(figsize=(13,5))\n",
    "plt.hist(list(permutations[\"n.unique.bigrams\"]),bins,color=\"darkblue\",edgecolor=\"darkblue\",alpha=.7,label=\"permuted\")\n",
    "plt.hist(list(bootstraps[\"n.unique.bigrams\"]),bins,color=\"darkred\",edgecolor=\"darkred\",alpha=.7,label=\"bootstraps\")\n",
    "plt.hist(list(bigramgens[\"n.unique.bigrams\"]),bins,color=\"darkgreen\",edgecolor=\"darkgreen\",alpha=.7,label=\"bigram-generated (length signatures)\")\n",
    "plt.axvline(x=n_cath8_bigrams,lw=3,color=\"purple\",label=\"Original CATH8\")\n",
    "plt.xlabel(\"Number of unique bigrams\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Bigram counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams and Bigrams Serial Distributions in CATH8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaghan observed that the unigrams and bigrams show markedly different distributions for different points in the corpus. Let's see if we can back that observation up with more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_per_sentence = [] # unigram counts per sentence\n",
    "\n",
    "## First build a list of unigrams, in the order in which they first occur in the corpus\n",
    "unigrams = []\n",
    "for sentence in cath8:\n",
    "    for word in sentence:\n",
    "        if word not in unigrams:\n",
    "            unigrams.append(word)\n",
    "    \n",
    "## Then make the counts\n",
    "counts = np.zeros( (len(cath8),len(unigrams)) )\n",
    "for i,sentence in enumerate(cath8):\n",
    "    for word in sentence:\n",
    "        if word in unigrams:\n",
    "            counts[i][unigrams.index(word)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(counts.T,aspect='auto',interpolation='none')\n",
    "plt.xlabel(\"Sentence # in CATH8\")\n",
    "plt.ylabel(\"Unigram (numbered by first occurrence)\")\n",
    "plt.colorbar(label=\"Number of occurrences\")\n",
    "plt.title(\"Unigram frequencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_per_sentence = [] # bigram counts per sentence\n",
    "\n",
    "cath8_concat = [\"#\"]\n",
    "for sentence in cath8:\n",
    "    cath8_concat+=sentence+[\"#\"]\n",
    "\n",
    "## First build a list of bigrams, in the order in which they first occur in the corpus\n",
    "bigrams = []\n",
    "for i in range(len(cath8_concat)-1):\n",
    "    bigr = \"%s.%s\"%(cath8_concat[i],cath8_concat[i+1])\n",
    "    if bigr not in bigrams:\n",
    "        bigrams.append(bigr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Then make the counts\n",
    "counts = np.zeros( (len(cath8),len(bigrams)) )\n",
    "for i,sentence in enumerate(cath8):\n",
    "    pad_sentence = [\"#\"]+sentence+[\"#\"]\n",
    "    for j in range(len(pad_sentence)-1):\n",
    "        bigr = \"%s.%s\"%(pad_sentence[j],pad_sentence[j+1])\n",
    "        counts[i][bigrams.index(bigr)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(counts.T,aspect='auto',interpolation='none')\n",
    "plt.xlabel(\"Sentence # in CATH8\")\n",
    "plt.ylabel(\"Bigram (numbered by first occurrence)\")\n",
    "plt.colorbar(label=\"Number of occurrences\")\n",
    "plt.title(\"Bigram frequencies\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
